---
title: System Design 101
updated: 2021-01-09 00:00
comments: true
mailchimp: true
layout: post
image: /images/system_design_cover.png
excerpt: Conceptos b√°sicos sobre System Design que cualquier Software Engineer deber√≠a entender.
---

Puedes leer este post en ingl√©s [aqu√≠](/system-design-101).

Casi todas las entrevistas que hago giran alrededor de [una peque√±a historia](storytelling-tips-technical-interviews). Y en casi todas acabo haciendo una simple pregunta: 

> ¬øPor qu√© es tan importante dise√±ar nuestros servicios para que no tengan estado? Especialmente si se ejecutan en un servidor.

![](/images/system_design_question.png)

Es incre√≠ble cu√°ntas personas contestan mal. Y cuando se equivocan, hago una segunda pregunta:

> ¬øQu√© es un Balanceador de Carga?

Casi todas las personas contestan que DevOps/SRE no es su campo. ¬°Esto est√° mal! !Muy mal¬° ¬°Caca!

Cualquier persona que haga Ingenier√≠a de Software (me da igual si te llamas developer, programador o programadora, jedi o incluso  ü¶Ñ unicornio) necesita entender al menos lo b√°sico sobre _System Design_. Sin importar su seniority o si su especialidad es frontend, backend, mobile, herramientas de productividad o no-code. 

1. M√°s que nada porque es esencial para tener un entendimiento hol√≠stico y sist√©mico sobre c√≥mo diferentes servicios y aplicaciones interact√∫an entre si.
   
2. Pero tambi√©n porque la infraestructura afecta la forma de programar. Tiene consecuencias y trade-offs. Obviamente.
   
3. Y tambi√©n porque no es tan dif√≠cil. No necesitas saber c√≥mo configurar un _Load Balancer_ en AWS o Google Cloud pero es importante entender qu√© es, por qu√© necesitr√≠as uno y cu√°ndo usarlo.

Este es el primer post de una serie (quiz√° tres) que cubre lo b√°sico sobre _System Design_. Todo esto te ayudar√° a encontrar mejores soluciones a los problemas que intentas resolver. No voy a entrar en demasiados detalles porque tendr√≠a que escribir libros enteros sobre cada tema. Pero s√≠ que voy a dejar muchos recursos para que puedas leer e investigar por tu cuenta.

[Comparte este post en üê¶ Twitter](https://twitter.com/intent/tweet?text={{page.title}}&url={{site.url}}{{page.url}}&via={{site.twitter_username}}&related={{site.twitter_username}}) o suscr√≠bete a mi newsletter **With a grain of salt** para recibir un email con novedades cada cierto tiempo.

{% include mailchimp.html %}

## Un cliente, un servidor y una base de datos entran en una cafeter√≠a

El setup m√°s t√≠pico que vas a encontrarte por ah√≠ es una aplicaci√≥n frontend (quiz√° usa [React](https://reactjs.org/)) que habla con un servicio backend (digamos que es una aplicaci√≥n basada en [Spring](https://spring.io/), escrita en [Kotlin](https://kotlinlang.org/), que sirve una [API REST](https://restfulapi.net/) y se ejecuta en un contenedor [Docker](https://www.docker.com/)) que a su vez se conecta a una base de datos (quiz√° [PostgreSQL](https://www.postgresql.org/)). Las tecnolog√≠as dan igual. Lo importante es: cliente, servidor y base de datos.

![](/images/system_design_basic.png)

Peeeeeero esta representaci√≥n del sistema es, en el mejor de los casos, incompleta. La verdad es que no existe solamente una instancia de la aplicaci√≥n frontend. Eso ser√≠a terrible porque significar√≠a que solamente una persona est√° usando tu producto. Y quiz√° esa persona seas t√∫. Lo que ocurre en realidad es que cada persona ejecuta una instancia diferente en su m√°quina (desktop o mobile) con diferentes condiciones de conectividad usando navegadores diferentes. Y eso que estamos ignorando por completo cosas como [DNS](https://www.cloudflare.com/learning/dns/what-is-dns/).

![](/images/system_design_dns.png)

Esta forma de ver el sistema es un poco m√°s precisa pero todav√≠a est√° lejos de la realidad. Al menos en cuanto a frontend se refiere. As√≠ que vamos a hablar de [qu√© pasa cuando escribes una url en un navegador y presionas Enter](https://medium.com/@maneesha.wijesinghe1/what-happens-when-you-type-an-url-in-the-browser-and-press-enter-bb0aa2449c1a).

## Y presionas Enter

Hoy en d√≠a las personas conectan su repositorio de [GitHub](http://github.com/stanete) a alg√∫n servicio tipo [Netlify](https://www.netlify.com/) y son felices. Pero dando un paso atr√°s debes saber que todo el contenido de una p√°gina web (HTML, CSS, JS y todos los dem√°s assets est√°ticos), debe estar almacenado en alg√∫n rinc√≥n oscuro de Internet. Netlify se encarga de esto y de mucho m√°s pero hace no mucho las personas ten√≠an que construir su aplicaci√≥n frontend y subir el contenido a un servicio de almacenamiento como [AWS S3](https://aws.amazon.com/s3/).

Pero no basta con almacenar el contenido; hay que servirlo de alguna manera y resulta que las [CDNs](https://www.cloudflare.com/learning/cdn/what-is-a-cdn/) son muy buenas para ello.

As√≠ es c√≥mo funciona paso a paso:

1. El navegador solicita al DNS (quiz√° [AWS Route 53](https://aws.amazon.com/es/route53/)) la direcci√≥n IP correspondiente a la url. Esa direcci√≥n IP corresponde a la CDN (tal vez [AWS Cloudfront](https://docs.aws.amazon.com/es_es/AmazonCloudFront/latest/DeveloperGuide/Introduction.html)).

2. El navegador solicita el contenido a la CDN. Si la CDN no lo tiene en la cach√©, lo solicita al almacenamiento (tal vez [AWS S3](https://aws.amazon.com/es/s3/)).

3. El almacenamiento devuelve el contenido a la CDN. A veces incluye una cabecera HTTP llamada Time-to-Live (TTL) que indica [cu√°nto tiempo se deber√≠a guardar el contenido en la cach√©](https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Expiration.html).

4. La CDN guarda el contenido en la cach√© y lo devuelve al navegador. El contenido permanece en la CDN hasta que expire el TTL.

5. Cuando otro navegador solicita el contenido, la CDN lo devuelve directamente desde la cach√©. Cuando el TTL expire, vuelta a empezar.

![](/images/system_design_cdn.png)

Hoy en d√≠a, si empiezas desde cero, probablemente te puedes saltar todo esto. Pero s√≠ que te vas a encontrar esta configuraci√≥n en la mayor√≠a de aplicaciones frontend que hay por ah√≠. As√≠ que [aqu√≠ tienes un post explicando c√≥mo utilizar AWS S3 y Cloudfront para hosting de una SPA est√°tica](https://paulstamatiou.com/hosting-on-amazon-s3-with-cloudfront/) y [aqu√≠ tienes otro explicando c√≥mo migrarlo todo a Netlify](https://paulstamatiou.com/moving-from-amazon-s3-to-netlify/). De nada.

A menos que tu p√°gina web tenga much√≠simo tr√°fico, no te vas a tener que preocupar con problemas de escalabilidad en el frontend durante bastante tiempo. ¬øPero qu√© pasa con el backend?

## Pon un Load Balancer en tu vida

No puedes controlar d√≥nde se ejecutan las diferentes instancias de la aplicaci√≥n frontend. Pero con los servicios backend es diferente. No s√≥lo puedes controlar cu√°ntas instancias se ejecutan en cualquier momento, sino que tambi√©n puedes cambiar la configuraci√≥n del servidor (como RAM o CPU) en el que se ejecuta cada instancia.

Puedes escalar el sistema verticalmente. Sobre todo cuando tienes poco tr√°fico. A√±ade m√°s memoria y/o CPU al servidor y ya estar√≠a. Pero como podr√°s imaginar, esto tiene un l√≠mite natural. Los costes aumentan muy r√°pido porque tanto la memoria como la capacidad de la CPU son bastante caras. 

Escalar el sistema horizontalmente suele ser m√°s deseable cuando tienes mucho tr√°fico. No quiere decir otra cosa que levantar tantas instancias como sea necesario. Pero esta soluci√≥n viene con un par de problemas. No te preocupes, tienen soluci√≥n. ¬øC√≥mo puedes tener un s√≥lo punto de entrada para que el dise√±o no se filtre al mundo exterior? ¬øC√≥mo puedes equilibrar la carga del tr√°fico entre todas las instancias? Tienes raz√≥n. Usando un [Load Balancer](https://www.nginx.com/resources/glossary/load-balancing/).

![](/images/system_design_load_balancer.png)

Con este setup, los clientes ya no pueden acceder directamente a los servicios backend. Se conectan a la IP p√∫blica del Load Balancer que distribuye uniformemente el tr√°fico y que se comunica internamente a trav√©s de IPs privadas.

Escalar horizontalmente tiene beneficios adicionales. Si una instancia se cae, el tr√°fico se enrutar√° a las instancias restantes. Si el tr√°fico crece r√°pidamente, puedes levantar autom√°ticamente tantas instancias como sea necesario y despu√©s apagarlas para controlar los costes.

Y aqu√≠ est√° la pregunta inicial. De nuevo.

> ¬øPor qu√© es tan importante dise√±ar nuestros servicios para que no tengan estado? Especialmente si se ejecutan en un servidor.

Suponiendo que el sistema est√° escalado horizontalmente, no se puede garantizar que un cliente acceda a la misma instancia dos veces seguidas. Es cierto que dependiendo del algoritmo del Load Balancer puedes tener cierta consistencia. Pero, ¬øqu√© pasa si una instancia falla por completo? El estado (los datos) se perder√≠a para siempre. Es por eso que el estado se almacena en una base de datos, lo que en alg√∫n momento puede convertirse en un problema porque solo hay una instancia. Y ese ser√° probablemente el pr√≥ximo cuello de botella.

## [Una de las dos cosas dif√≠ciles](https://www.karlton.org/2017/12/naming-things-hard/)

> Solo hay dos cosas dif√≠ciles en Ciencias de la Computaci√≥n: invalidaci√≥n de cach√© y nombrar cosas. -- Phil Karlton

Puedes eliminar parte de la carga de la base de datos utilizando una [cach√©](https://aws.amazon.com/caching/), que no es m√°s que una capa de almacenamiento de datos temporal, como [Redis](https://redis.io/topics/introduction) o [Memcached](https://memcached.org/). En general, la cach√© almacena el resultado de respuestas pesadas o datos a los que se accede con bastante frecuencia. Es mucho m√°s r√°pida que la base de datos porque almacena los datos en la memoria. Peeeeero, debes tener cuidado: si se reinicia un servidor de cach√©, todos los datos se perder√°n. Obviamente.

¬øC√≥mo funciona? 

1. Despu√©s de recibir una request, el servicio backend primero verifica si la cach√© tiene la respuesta disponible.
   
2. Si no la tiene, hace una consulta a la base de datos, almacena la respuesta en la cach√© y la env√≠a de vuelta al cliente.

3. La pr√≥xima vez que un cliente solicite los mismos datos, se devolver√°n directamente desde la cach√© sin consultar la base de datos.

Esto tambi√©n sirve para servicios externos.

![](/images/system_design_cache.png)

Es mejor utilizar la cach√© cuando los datos se leen con frecuencia pero se modifican con poca frecuencia. Y no te olvides de implementar una pol√≠tica de expiraci√≥n o expiration policy. Una vez que los datos expiran, se eliminan de la cach√©. La pol√≠tica de expiraci√≥n ayuda a mantener los datos de la cach√© sincronizados con la base de datos, pero no resuelve problemas de consistencia. Invalidar la cach√© cuando lo necesites es un reto dif√≠cil y hablar√© sobre ello en un siguiente post.

## La guerra de los clones

Usar una cach√© mola, pero en alg√∫n momento no ser√° suficiente. La base de datos sigue siendo una √∫nica instancia. Un [punto √∫nico de fallo](https://es.wikipedia.org/wiki/Single_point_of_failure) y un cuello de botella.

Las operaciones de lectura suelen ser m√°s frecuentes que las de escritura. Cuando ese sea el caso puedes usar [replicaci√≥n](https://es.wikipedia.org/wiki/Replicaci%C3%B3n_(inform%C3%A1tica)). Es una t√©cnica para manejar m√∫ltiples instancias de una base de datos, generalmente con una relaci√≥n principal/secundaria entre la original y las copias. La base de datos principal generalmente admite solo operaciones de escritura, mientras que las copias solo admiten operaciones de lectura.

![](/images/system_design_db_replication.png)

La replicaci√≥n tiene m√∫ltiples ventajas. Vas a tener mejor rendimiento, confiabilidad y alta disponibilidad. Las operaciones de lectura se distribuyen entre las instancias secundarias, los datos nunca se pierden porque se replican en varias ubicaciones. Incluso si la instancia secundaria se desconecta o apaga, a√∫n puedes acceder a los datos de otras ubicaciones.

Si todas las secundarias se desconectan o apagan, las operaciones de lectura se dirigir√°n temporalmente a la base de datos principal. Cuando al menos una instancia secundaria est√© funcionando correctamente, las operaciones de lectura se redireccionar√°n de nuevo a ella.

Si la instancia principal se desconecta o apaga, se promover√° una base de datos secundaria y se convertir√° en la principal. Una nueva instancia reemplazar√° la antigua base de datos secundaria. Esto es m√°s dif√≠cil de lo que parece porque en la vida real los datos pueden estar sincronizados o no. Y probablemente haya que hacer magia oculta para resolver el problema sin perder datos.

Si todas las instancias, principal y secundarias, se caen, tienes un gran problema.

La replicaci√≥n es solo una de las muchas t√©cnicas para escalar la base de datos horizontalmente. [Sharding](https://www.digitalocean.com/community/tutorials/understanding-database-sharding) es otra.

## La magia siempre ocurre as√≠ncronamente

Algunas de las tareas que ejecutan los servicios backend, como enviar una notificaci√≥n o procesar una foto, no necesitan ocurrir de inmediato. Se pueden ejecutar de forma asincr√≥nica. Sin embargo, las instrucciones para saber qu√© tarea ejecutar, deben almacenarse en alg√∫n lugar hasta que un servicio est√© listo para ejecutarla. Para ello puedes usar una cola de tareas o [task Queue](https://redislabs.com/ebook/part-2-core-concepts/chapter-6-application-components-in-redis/6-4-task-queues/) tambi√©n llamada cola de mensajes o [message Queue](https://aws.amazon.com/message-queue/). En realidad [hay diferencias entre task Queue y message Queue](https://stackoverflow.com/questions/10075817/message-queue-vs-task-queue-difference) pero voy a ignorarlas por ahora. Puede que hayas o√≠do hablar de [RabittMQ](https://www.rabbitmq.com/), [AWS SQS](https://aws.amazon.com/es/sqs/) o [Celery](https://docs.celeryproject.org/en/stable/).

![](/images/system_design_queue_workers.png)

La arquitectura b√°sica de una cola es simple. Algunos servicios, llamados producers o publishers, crean mensajes y los publican en la cola. Otros servicios, llamados consumers o suscribers, se conectan a la cola y consumen los mensajes uno por uno para realizar las tareas necesarias. El propio mensaje contiene informaci√≥n sobre qu√© tarea se va a ejecutar y datos para que la tarea se pueda ejecutar con √©xito.

> Solo hay dos cosas dif√≠ciles en los sistemas distribuidos: 
> 2. Entregar un mensaje exactamente una vez.
> 
> 1. Garantizar el orden de los mensajes.
> 
> 2. Entregar un mensaje exactamente una vez.

Usar una message Queue viene con sus propios problemas. Es dif√≠cil asegurarse de que un mensaje se entregar√° [exactamente una vez](https://bravenewgeek.com/you-cannot-have-exactly-once-delivery/). Y es igualmente dif√≠cil garantizar que todos los mensajes se consumen en el orden deseado.

## Un nuevo comienzo

Ahora s√≠. Esta es una vista m√°s sist√©mica y hol√≠stica sobre c√≥mo interact√∫an los diferentes servicios que lo componen. En t√©rminos de escalabilidad, tu producto tiene que tener bastante √©xito para que necesites m√°s que esto. Pero todav√≠a no he tratado de temas como rate limiters, seguridad o autenticaci√≥n.

![](/images/system_design_complete.png)

Adem√°s, todav√≠a hay dos monolitos: uno para el frontend y otro para el backend. A√∫n necesito hablar sobre las implicaciones de tener m√∫ltiples servicios interactuando entre s√≠ cuando decidas romper esos monolitos, backends for frontend, microfrontends o renderizaci√≥n del lado del servidor (SSR). En los pr√≥ximos dos posts cubrir√© estos y otros temas como m√∫ltiples centros de datos, redes privadas virtuales o sharding.

[Comparte este post en üê¶ Twitter](https://twitter.com/intent/tweet?text={{page.title}}&url={{site.url}}{{page.url}}&via={{site.twitter_username}}&related={{site.twitter_username}}) o suscr√≠bete a mi newsletter **With a grain of salt** para recibir un email con novedades cada cierto tiempo.
