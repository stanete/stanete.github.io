---
title: Introducci√≥n a machine learning pero sin hype
updated: 2017-01-15 16:48
comments: true
mailchimp: true
---

> Primeros pasos, aprendizaje supervisado & clasificaci√≥n

Vamos a saltarnos la parte de explicar qu√© es [Machine Learning](https://es.wikipedia.org/wiki/Aprendizaje_autom%C3%A1tico) y para qu√© sirve. Vamos a empezar directamente con cosas m√°s pr√°cticas.

PD: En pr√≥ximos posts hablaremos sobre Deep Learning tambi√©n üòè.

## ¬øC√≥mo se empieza?

**Algoritmos**. Necesitamos aprender c√≥mo funcionan los algoritmos que ya existen (al menos algunos de ellos) y entender en qu√© situaciones es mejor utilizar uno u otro.

No vamos a programar esos algoritmos sino que vamos a usar python y varias librer√≠as opensource para usarlos directamente y verlos en acci√≥n (s√≠ que vamos a tratar de entender c√≥mo funcionan).

A estos algoritmos tambi√©n se les llama **modelos**. Un modelo sirve para representar de forma sencilla una realidad mucho m√°s compleja. El problema es que eso nunca es exacto y siempre va a existir un **error**. Por eso, nuestro trabajo ser√° maximizar la precisi√≥n con la que un modelo es capaz de clasificar, predecir o describir esa realidad ü§î.

Para empezar necesitamos tener instalado python y varios paquetes:

- [python 3.5 o 3.6](https://www.python.org/)
- [numpy](http://www.numpy.org/)
- [scipy](https://www.scipy.org/)
- [matplotlib](http://matplotlib.org/)
- [scikit-learn](http://scikit-learn.org/)

PD 1: Si los instalamos en este orden via *pip*, no deber√≠amos tener ning√∫n problema.

PD 2: Yo utilizo [PyCharm](https://www.jetbrains.com/pycharm/) y tengo todo dentro de un [virtualenv](https://virtualenv.pypa.io/en/stable/).

PD 3: Los ejemplos de c√≥digo est√°n hechos para que se puedan seguir con una consola de python en el orden que se muestran.

<div class="divider"></div>

## El proceso

A la hora de intetar resolver un problema en Machine Learning casi siempre debemos seguir el mismo proceso:

1. Recolectar y preparar datos
2. Escojer un modelo
3. Entrenar el modelo con los datos
4. Probar el modelo

<div class="divider"></div>

## Recolectar y preparar datos

Es improbable (no imposible) que nosotros desarrollemos un nuevo algoritmo que de mejores resultados que los que ya existen. Pero un algoritmo sin datos no sirve de nada. Un algoritmo puede dar resultados muy diferentes dependiendo de la estructura de los datos con los que lo alimentamos. Por eso gran parte de nuestro trabajo ser√° recolectar y manipular datos. A esto se le llama *feature engineering*. Una feature o **caracter√≠stica** es cualquier medida de nuestros datos.

> Una buena caracter√≠stica es simple, independiente e informativa.

Para empezar vamos a usar el dataset de las flores Iris, un conjunto de datos cl√°sico de los a√±os treinta. Hoy en d√≠a, las diferentes especies de Iris se clasificar√≠an por sus firmas gen√≥micas pero en la d√©cada de 1930, el ADN no hab√≠a sido identificado como el portador de la informaci√≥n gen√©tica, pero s√≠ que se las pod√≠an clasificar por su morfolog√≠a:

- Longitud del s√©palo (sepal length (cm))
- Anchura del s√©palo (sepal width (cm))
- Longitud de los p√©talos (petal length (cm))
- Anchura de los p√©talos (petal width (cm))

Lo bueno es que este dataset viene dentro de *scikit-learn*:

```python
from sklearn import datasets

iris = datasets.load_iris()
```

Para simplificarlo al m√°ximo, vamos a trabajar solamente con las primeras dos caracter√≠sticas:

```python
features = iris.data[:, :2]

feature_names = iris.feature_names[:2]

print(feature_names)

#¬†['sepal length (cm)', 'sepal width (cm)']
```

Los datos de este dataset est√°n etiquetados (labeled). Eso quiere decir que cada conjunto de caracter√≠sticas corresponde a una subespecie de Iris:

``` python
labels = iris.target

labels_names = iris.target_names

print(labels_names)

# ['setosa' 'versicolor' 'virginica']
```

Vamos a visualizar estos datos con *matplotlib*. Representamos cada subespecie por separado con un color difernte:

```python
from matplotlib import pyplot as plt

for l, c in zip(range(3), "brw"):
    plt.scatter(features[labels == l, 0],
                features[labels == l, 1],
                c=c)

plt.xlabel(feature_names[0])
plt.ylabel(feature_names[1])

plt.show()
```

![figure_1](../images/1_figure_1.png)

Visualizar los datos nos puede dar pistas sobre qu√© modelo utilizar. Por eso, **siempre tenemos que visualizar los datos**. El problema es que los humanos somos muy buenos visualizando datos en 2 e incluso en 3 dimensiones, pero no m√°s. Para esto hemos elegido s√≥lo dos caracter√≠sticas. En pr√≥ximos posts hablaremos sobre c√≥mo escoger las caracer√≠sticas que m√°s informaci√≥n aportan a la hora de visualizar los datos.

Por √∫ltimo, necesitamos **dividir** este dataset en datos para entrenar el modelo y datos para testearlo. M√°s adelante entenderemos por qu√© esto es extremadamente importante.

```python
from sklearn.model_selection import train_test_split

features_train, features_test, \
    labels_train, labels_test = train_test_split(
        features, labels,
        train_size=0.8,
        test_size=0.2,
        random_state=0)
```

<div class="divider"></div>

## Escojer un modelo

Dependiendo de la situaci√≥n debemos usar un modelo u otro. Uno de los fallos de alguien que empieza en Machine Learning es pensar que las redes neuronales son la soluci√≥n para todo, y eso no cierto.

El problema que estamos intentando resolver es de **aprendizaje supervisado**. Eso quiere decir que dados ejemplos etiquetados (labeled), podemos dise√±ar una regla que eventualmente se aplicar√° a otros ejemplos.

Concretamente, este es un problema de **clasificaci√≥n**. Una vez que hayamos encontrado esa regla, podremos clasificar nuevas flores Iris seg√∫n su subespecie. Para encontrar esa regla o serie de reglas debemos usar un modelo llamado **clasificador**.

Con *scikit-learn* tenemos disponibles varios clasificadores. Nosotros vamos a usar un **clasificador bayesiano ingenuo** o **Na√Øve Bayes**, uno de los clasificadores m√°s utilizados por su simplicidad y rapidez. Qui√©n era Bayes y por qu√© su clasificador es ingenuo lo veremos en pr√≥ximos posts üòÖ.

```python
from sklearn.naive_bayes import GaussianNB

clf = GaussianNB()
```

Vamos a alimentar al clasificador con los datos que hemos dividio:

```python
clf.fit(features_train, labels_train)
```

El clasificador ha construido unas **fronteras de decisi√≥n** o **superficies de decisi√≥n** para dividir el espacio vectorial en varios conjuntos, uno para cada subespecie de Iris. El clasificador clasificar√° todos los puntos de un lado de cada frontera de decisi√≥n como pertenecientes a una subespecie.

Vamos a visualizar las **fronteras de decisi√≥n** junto a los datos, aunque no nos vamos a preocupar por los detalles del c√≥digo por ahora:

```python
import numpy as np

# Visualizar las fronteras de decisi√≥n.
h = .02
x_min = features[:, 0].min() - 1
x_max = features[:, 0].max() + 1
y_min = features[:, 1].min() - 1
y_max = features[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                     np.arange(y_min, y_max, h))

Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])

Z = Z.reshape(xx.shape)
plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)

# Visualizar tambi√©n los datos.
for l, c in zip(range(3), "brw"):
    plt.scatter(features[labels == l, 0],
                features[labels == l, 1],
                c=c)
plt.xlabel(feature_names[0])
plt.ylabel(feature_names[1])

plt.xlim(xx.min(), xx.max())
plt.ylim(yy.min(), yy.max())
plt.show()
```

![figure_2](../images/1_figure_2.png)

Dependiendo de qu√© lado de cada frontera est√© una nueva flor Iris, el clasificador le asignar√° una etiqueta u otra.

<div class="divider"></div>

## Poner el modelo a prueba

Ya hemos entrenado el clasificador pero no sabemos c√≥mo de preciso es a la hora de clasificar nuevas flores Iris. Para averiguarlo vamos a testear el clasificador con los datos que hemos dividido antes. Vamos a hacer que nuestro clasificador determine las etiquetas de algunas flores de Iris y compararlo con sus etiquetas reales.

```python
from sklearn.metrics import accuracy_score

labels_predict = clf.predict(features_test)

accuracy = accuracy_score(labels_predict, labels_test)

print("Accuracy: %.2f" % (accuracy))

# Accuracy: 0.73
```

0.73 es mejor que la casualidad, pero no demasiado teniendo en cuenta que la precision se mide entre 0 y 1.

Vamos a intentar entrenar nuestro modelo con las 4 caracter√≠sticas y ver si la precisi√≥n del clasificador mejora:

```python
# Las 4 caracter√≠sticas.
features = iris.data

# Dividir datos.
features_train, features_test, \
    labels_train, labels_test = train_test_split(
        features, labels,
        train_size=0.8,
        test_size=0.2,
        random_state=0)

# Alimentar el clasificador con los datos de entrenamiento.
clf.fit(features_train, labels_train)

# Predecir etiquetas sobre los datos de testeo.
labels_predict = clf.predict(features_test)

# Calcular precisi√≥n.
accuracy = accuracy_score(labels_predict, labels_test)

print("Accuracy: %.2f" % (accuracy))

# Accuracy: 0.97
```

Wow! La precisi√≥n ha mejorado hasta 0.97. Como vemos, no todo depende del clasificador que usemos.

<div class="divider"></div>

## Vamos a terminar esto

Machine Learning no es una caja m√°gica, sino c√°lculo, √°lgebra, estad√≠stica y c√≥digo. Esto es s√≥lo el principio y en pr√≥ximos posts vamos a ver m√°s modelos y m√°s tipos de problemas. Cualquier feedback es bienvenido!

PD: Te puedes suscribir y recibir un email cada vez que haya un nuevo post.
